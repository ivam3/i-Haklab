#!/usr/bin/bash
IFS=$'\n\t'
trap ctrl_c 2
source ${HOME}/.local/etc/i-Haklab/variables
source $iHETC/functions

chk-pkg ffmpeg ffmpeg
chk-pkg termimage termimage
banner

key=$(grep "OPENAI_KEY" $iHETC/variables)
[[ -z $OPENAI_KEY ]] || [[ "$1" == "setkey" ]] && {
  echo -en "$Y[!]$W OpenAI API key needed$Y |$W Get it on https://platform.openai.com/account/api-keys\n$Y ╰──➤$W "
  while read apikey && [ -z $apikey ];do
    echo -en "$Y ╰──➤$W "
  done
  sed -i "s|$key|OPENAI_KEY=\"$apikey\"|" $iHETC/variables
  source $iHETC/variables
}

CHAT_INIT_PROMPT="You are ChatGPT, a Large Language Model trained by OpenAI. You will be answering questions from users. You answer as concisely as possible for each response (e.g. don’t be verbose). If you are generating a list, do not have too many items. Keep the number of items short. Before each user prompt you will be given the chat history in Q&A form. Output your answer directly, with no labels in front. Do not start your answers with A or Anwser. You were trained on data up until 2021"

# Error handling function
# $1 should be the response body
handleError() {
	if echo "$1" | jq -e '.error' >/dev/null; then
		echo -en "${R}E: Your request to Open AI API failed:$W $(echo $1 | jq -r '.error.type')"
		echo $1 | jq -r '.error.message'
		exit 1
	fi
}

# parse command line arguments
while [[ "$#" -gt 0 ]]; do
	case $1 in
	-t | --temperature)
		TEMPERATURE="$2"
		shift
		shift
		;;
	--max-tokens)
		MAX_TOKENS="$2"
		shift
		shift
		;;
	-m | --model)
		MODEL="$2"
		shift
		shift
		;;
	-s | --size)
		SIZE="$2"
		shift
		shift
		;;
	-c | --chat-context)
		CONTEXT=true
		shift
		shift
		;;
	*)
		echo -e "${R}E:$W Unknown parameter: $1"
		exit 1
		;;
	esac
done

# set defaults
TEMPERATURE=${TEMPERATURE:-0.7}
MAX_TOKENS=${MAX_TOKENS:-1024}
MODEL=${MODEL:-text-davinci-003}
SIZE=${SIZE:-512x512}
CONTEXT=${CONTEXT:-false}

echo -e "Welcome to ${C}chatgpt$W. You can quit with '${G}exit$W'."
running=true

# create history file
if [ ! -f ~/.chatgpt_history ]; then
	touch ~/.chatgpt_history
	chmod a+rw ~/.chatgpt_history
fi

while $running; do
	echo -en "$G\n$USER$W\n" && read prompt

	if [ "$prompt" == "exit" ];then
		running=false
    echo -en "$B\nGoodbye $Y$USER$B Have a great hacking day!!.$W"
	elif [[ "$prompt" =~ ^image: ]]; then
		image_response=$(curl https://api.openai.com/v1/images/generations \
			-sS \
			-H 'Content-Type: application/json' \
			-H "Authorization: Bearer $OPENAI_KEY" \
			-d '{
    		"prompt": "'"${prompt#*image:}"'",
    		"n": 1,
    		"size": "'"$SIZE"'"
			}')
		handleError "$image_response"
		image_url=$(echo $image_response | jq -r '.data[0].url')
		echo -en "${C}chatgpt$W Your image was created. \n$Y\nLink:$W ${image_url}\n$Y\nIt could be open in:$W\n"
    select opc in termuxAPP termuxGUI androidAPP browser wayland skip; do
      curl -sS $image_url -o ${TMPDIR}/temp_image.png
      if [ "$opc" == "termuxAPP" ]; then
        ffmpeg -i ${TMPDIR}/temp_image.png -vf scale=512:512 ${TMPDIR}/temp_image512.png &>/dev/null
			  termimage ${TMPDIR}/temp_image512.png
      elif [ "$opc" == "wayland" ]; then
        [[ -e ${TMPDIR}/wayland-0 ]] || {
          export DISPLAY=:0
          export XDG_RUNTIME_DIR=${TMPDIR}
          ! command -v termux-x11 &>/dev/null || { Xbin="termux-x11";} || { Xbin="Xwayland";}
          $(command -v $Xbin) :0 >/dev/null &
          sleep 5
        }
        ristretto --display=:0 ${TMPDIR}/temp_image.png
      elif [ "$opc" == "termuxGUI" ]; then
        termux-gui-view -n 15 ${TMPDIR}/temp_image.png 2>/dev/null
      elif [ "$opc" == "androidAPP" ]; then
        termux-share ${TMPDIR}/temp_image.png
      elif [ "$opc" == "browser" ]; then
        termux-open-url "${image_url}"
      else
        break
      fi
    done
    rm ${TMPDIR}/*.png

  elif [[ "$prompt" == "history" ]]; then
		echo -e "\n$(bat ~/.chatgpt_history)"
	elif [[ "$prompt" == "models" ]]; then
		models_response=$(curl https://api.openai.com/v1/models \
			-sS \
			-H "Authorization: Bearer $OPENAI_KEY")
		handleError "$models_response"
		models_data=$(echo $models_response | jq -r -C '.data[] | {id, owned_by, created}')
		echo -e "\n${C}chatgpt$W This is a list of models currently available at OpenAI API:\n ${models_data}"
	elif [[ "$prompt" =~ ^model: ]]; then
		models_response=$(curl https://api.openai.com/v1/models \
			-sS \
			-H "Authorization: Bearer $OPENAI_KEY")
		handleError "$models_response"
		model_data=$(echo $models_response | jq -r -C '.data[] | select(.id=="'"${prompt#*model:}"'")')
		echo -e "\n${C}chatgpt$W Complete data for model: ${prompt#*model:}\n ${model_data}"
	else
		# escape quotation marks
		escaped_prompt=$(echo "$prompt" | sed 's/"/\\"/g')
		# escape new lines
		request_prompt=${escaped_prompt//$'\n'/' '}

		if [ "$CONTEXT" = true ]; then
			# build chat context
			if [ -z "$chat_context" ]; then
				chat_context="$CHAT_INIT_PROMPT\nQ: $escaped_prompt"
			else
				chat_context="$chat_context\nQ: $escaped_prompt"	
			fi
			request_prompt="${chat_context//$'\n'/\\n}"	
		fi

		# request to OpenAI API
		response=$(curl https://api.openai.com/v1/completions \
			-sS \
			-H 'Content-Type: application/json' \
			-H "Authorization: Bearer $OPENAI_KEY" \
			-d '{
  			"model": "'"$MODEL"'",
  			"prompt": "'"${request_prompt}"'",
  			"max_tokens": '$MAX_TOKENS',
  			"temperature": '$TEMPERATURE'
			}')
		handleError "$response"
		response_data=$(echo $response | jq -r '.choices[].text' | sed '1,2d; s/^A://g')
		echo -e "\n${C}chatgpt$W"
    echo "${response_data}"|bat  -f --theme 'Visual Studio Dark+'

		if [ "$CONTEXT" = true ]; then
			# add response to chat context as answer
			chat_context="$chat_context${chat_context:+\n}\nA: ${response_data//$'\n'/\\n}"
			# check prompt length, 1 word =~ 1.3 tokens
			# reserving 100 tokens for next user prompt
			while (( $(echo "$chat_context" | wc -c)*1,3 > (MAX_TOKENS-100) )); do
				# remove first/oldest QnA from prompt
				chat_context=$(echo "$chat_context" | sed -n '/Q:/,$p' | tail -n +2)
				# add init prompt so it is always on top
				chat_context="$CHAT_INIT_PROMPT $chat_context"
			done
		fi

		timestamp=$(date +"%d/%m/%Y %H:%M")
		echo -e "$timestamp $prompt \n$response_data \n" >>~/.chatgpt_history
	fi
done
